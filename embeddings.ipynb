{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1XZCCgZ_m-4",
        "outputId": "7ad92ea0-707a-4273-b248-3b8e9c0c9afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we are going to use a BERT-like model to create embeddings for words."
      ],
      "metadata": {
        "id": "vOIJkjJSEvmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1xSDQSr_rxP",
        "outputId": "36aa63ee-fc92-46b5-9f58-df69fc28c0cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the tokens."
      ],
      "metadata": {
        "id": "v9uvstSYE4co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer('hello world', return_tensors='pt')\n",
        "output = model(**tokens)[0]\n",
        "\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc082D4rADUm",
        "outputId": "26a444b4-693c-4dcd-cf16-0033b349380d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 384])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, each token was embedded into a tensor of dimension 384. Note that the final embeddings contain contextual information of their neighboors, as they are the outputs from a BERT model.\n",
        "\n",
        "We can also generate sentence embeddings, in similar fashion."
      ],
      "metadata": {
        "id": "x-3d1JdyFCEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "output = model.encode(\"sentence embedding\")\n",
        "\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kaP_twhB80y",
        "outputId": "0aff56de-2966-419a-9527-43a90efe39b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the sentence was embedded into a 768-shaped tensor."
      ],
      "metadata": {
        "id": "vPxNMrmpFfzy"
      }
    }
  ]
}