{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HbF_F45GJC2b"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMbgJmg5JJmi"
   },
   "source": [
    "Creating a list of models to inspect their respective tokenization schemes. Here, the following models and tokenization methods are considered:\n",
    "\n",
    "- ``google-bert/bert-base-uncased``: WordPiece,\n",
    "- ``FacebookAI/roberta-base``: BPE,\n",
    "- ``google-t5/t5-base``: SentencePiece,\n",
    "- ``mistralai/Mistral-7B-v0.1``: BPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kK8O8QrRBUfJ"
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"google-bert/bert-base-uncased\",\n",
    "    \"FacebookAI/roberta-base\",\n",
    "    \"google-t5/t5-base\",\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8SW76AyJkwC"
   },
   "source": [
    "Creating a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IZcfW4bOCS1E"
   },
   "outputs": [],
   "source": [
    "prompt = \"Tokeinization IS the start of LLMs!!!! 241752412##@%&@1\"\n",
    "\n",
    "def print_tokens(model_name, text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    print(f'model: {model_name}')\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        print(token)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iA8H5vZaOWZg"
   },
   "source": [
    "Trying some tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_j69oNsrL-at"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: google-bert/bert-base-uncased\n",
      "to\n",
      "##kei\n",
      "##ni\n",
      "##zation\n",
      "is\n",
      "the\n",
      "start\n",
      "of\n",
      "ll\n",
      "##ms\n",
      "!\n",
      "!\n",
      "!\n",
      "!\n",
      "241\n",
      "##75\n",
      "##24\n",
      "##12\n",
      "#\n",
      "#\n",
      "@\n",
      "%\n",
      "&\n",
      "@\n",
      "1\n",
      "\n",
      "\n",
      "model: FacebookAI/roberta-base\n",
      "T\n",
      "oke\n",
      "in\n",
      "ization\n",
      "ĠIS\n",
      "Ġthe\n",
      "Ġstart\n",
      "Ġof\n",
      "ĠLL\n",
      "Ms\n",
      "!!!!\n",
      "Ġ24\n",
      "175\n",
      "24\n",
      "12\n",
      "##\n",
      "@\n",
      "%\n",
      "&\n",
      "@\n",
      "1\n",
      "\n",
      "\n",
      "model: google-t5/t5-base\n",
      " To\n",
      "ke\n",
      "in\n",
      "ization\n",
      " IS\n",
      " the\n",
      " start\n",
      " of\n",
      " L\n",
      "LM\n",
      "s\n",
      "!!!!\n",
      " 24\n",
      "1\n",
      "75\n",
      "24\n",
      "12\n",
      "##\n",
      "@\n",
      "%\n",
      "&\n",
      "@\n",
      "1\n",
      "\n",
      "\n",
      "model: mistralai/Mistral-7B-v0.1\n",
      " To\n",
      "ke\n",
      "in\n",
      "ization\n",
      " IS\n",
      " the\n",
      " start\n",
      " of\n",
      " LL\n",
      "Ms\n",
      "!!!!\n",
      " \n",
      "2\n",
      "4\n",
      "1\n",
      "7\n",
      "5\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "##\n",
      "@\n",
      "%\n",
      "&\n",
      "@\n",
      "1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print_tokens(model, prompt)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
