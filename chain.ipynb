{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ielnceT--ldR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "from langchain_classic import hub\n",
        "from langchain_classic.agents import AgentExecutor, create_react_agent\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_download"
      },
      "source": [
        "Dowloading the Llama 3.1 8B Instruct model in GGUF format directly from Hugging Face Hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "38gkiQTPcy4O"
      },
      "outputs": [],
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=\"MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
        "    filename=\"Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf\",\n",
        "    local_dir=\".\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_init_llm"
      },
      "source": [
        "Loading the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PruwnvBD-XyN"
      },
      "outputs": [],
      "source": [
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf\",\n",
        "    n_gpu_layers=-1,\n",
        "    max_tokens=500,\n",
        "    n_ctx=1024,\n",
        "    temperature=0,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_templates"
      },
      "source": [
        "With `langchain`, it is possible to create piplines involving LLMs. With that, three templates were created as a sequential chain: one for the title, one for character description, and one for the final story, given an initial prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2YKIo35mBZTs"
      },
      "outputs": [],
      "source": [
        "template_title = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Create a short, creative title for a story about {summary}. Only return the title.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
        "\n",
        "title_prompt = ChatPromptTemplate.from_template(template_title)\n",
        "\n",
        "template_character = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Describe the main character of a story about {summary} with the title {title}. Use only two sentences.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
        "\n",
        "character_prompt = ChatPromptTemplate.from_template(template_character)\n",
        "\n",
        "template_story = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Create a story about {summary} with the title {title}. The main character is: {character}. Only return the story and it cannot be longer than one paragraph.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
        "\n",
        "story_prompt = ChatPromptTemplate.from_template(template_story)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_chain"
      },
      "source": [
        "Running the chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "baYT7K8ye7Z6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary\n",
            "A boy who fought Kung-Fu\n",
            "title\n",
            "\"The Dragon's Fury: A Kung-Fu Legend\"\n",
            "character\n",
            "The main character, a young boy named Ling, is a skilled and fierce Kung-Fu master who wields the power of the dragon. With his unwavering determination and unrelenting fury, Ling is destined to become a legendary hero in the world of Kung-Fu.\n",
            "story\n",
            "The Dragon's Fury: A Kung-Fu Legend. Ling, a young boy with an unyielding determination and unrelenting fury, is a skilled and fierce Kung-Fu master who wields the power of the dragon. With his unwavering dedication to justice and his unrelenting passion for Kung-Fu, Ling is destined to become a legendary hero in the world of Kung-Fu.\n"
          ]
        }
      ],
      "source": [
        "title_step = title_prompt | llm | StrOutputParser()\n",
        "\n",
        "character_step = (\n",
        "    {\"summary\": lambda x: x[\"summary\"], \"title\": lambda x: x[\"title\"]}\n",
        "    | character_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "story_step = story_prompt | llm | StrOutputParser()\n",
        "\n",
        "chain = (\n",
        "    RunnableParallel(summary=RunnablePassthrough())\n",
        "    | RunnablePassthrough.assign(title=title_step)\n",
        "    | RunnablePassthrough.assign(character=character_step)\n",
        "    | RunnablePassthrough.assign(story=story_step)\n",
        ")\n",
        "\n",
        "out = chain.invoke(\"A boy who fought Kung-Fu\")\n",
        "\n",
        "for key in list(out.keys()):\n",
        "    print(key)\n",
        "    print(out[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_groq"
      },
      "source": [
        "It is also possible to create agents. For that, the Llama 3.3 70B model is going to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2wvY8wBgmb2m"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "llm_agent = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_tools"
      },
      "source": [
        "Equiping the agent with DuckDuckGo Search and a math tool to handle external calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0F8ji3cXhswC"
      },
      "outputs": [],
      "source": [
        "search = DuckDuckGoSearchResults()\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"duckduckgo\",\n",
        "    description=\"Use this for current events or technical facts you don't know.\",\n",
        "    func=search.run,\n",
        ")\n",
        "\n",
        "tools = load_tools([\"llm-math\"], llm=llm_agent)\n",
        "tools.append(search_tool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_prompt_pull"
      },
      "source": [
        "Loading a standard ReAct (Reason + Act) prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uXKxI8i8lnY-"
      },
      "outputs": [],
      "source": [
        "agent_prompt = hub.pull(\"hwchase17/react\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_executor"
      },
      "source": [
        "Instantiating the agent model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3wI77Jo-mi3N"
      },
      "outputs": [],
      "source": [
        "agent = create_react_agent(llm_agent, tools, agent_prompt)\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_invoke_agent"
      },
      "source": [
        "Asking a simple question for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9g49awRimkVx"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Answer: The current price of a 14-inch MacBook Pro in USD is $1,399, and you can find the latest pricing information on websites such as https://appleinsider.com/articles/26/01/05/apples-m5-macbook-pro-drops-to-1399-200-off-as-ces-2026-kicks-off."
          ]
        }
      ],
      "source": [
        "res = agent_executor.invoke({\"input\": \"What is the current price of a 14-inch MacBook Pro in USD? Return me the price and a single updated website with this information.\"})\n",
        "print(res['output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_llm_direct"
      },
      "source": [
        "As a baseline comparison, the LLM is used directly without tools to see how it affects the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qdxc6xMKs9my"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"As of my knowledge cutoff in 2023, the prices for a 14-inch MacBook Pro may vary...\""
          ]
        }
      ],
      "source": [
        "print(llm_agent.invoke(\"What is the current price of a 14-inch MacBook Pro in USD? Return me the price and a single updated website with this information.\"))"
      ]
    }
  ]
}
