{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Uydx6Q5OBA8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will use the Rotten Tomatoes dataset, for classifying comments about movies in positive or negative reviews."
      ],
      "metadata": {
        "id": "UZOBxbGvUg65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('rotten_tomatoes')"
      ],
      "metadata": {
        "id": "nDENO5KqOFHp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Representation models"
      ],
      "metadata": {
        "id": "GzkV5TspUUG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will use a representation model - based on BERT - which was pre-trained on Twitter comments. The model will not be fine-tuned, as of now."
      ],
      "metadata": {
        "id": "vwNC2oP-UY3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "model = pipeline(\n",
        "    task=\"sentiment-analysis\",\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    device=\"cuda:0\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eNVh62-ONnJ",
        "outputId": "c6f42614-e5d8-41c3-cd34-031ab727b553"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the predictions."
      ],
      "metadata": {
        "id": "Jcb5BZSZVAF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    \"negative\": 0,\n",
        "    \"neutral\": 1,\n",
        "    \"positive\": 1\n",
        "}\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "for output in model(KeyDataset(dataset[\"test\"], \"text\")):\n",
        "    label_text = output[\"label\"]\n",
        "    y_pred.append(label_map[label_text])"
      ],
      "metadata": {
        "id": "MdYKdrbvPfvP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the classification report."
      ],
      "metadata": {
        "id": "4wuSpWh5VDTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "performance_roberta = classification_report(\n",
        "    dataset['test']['label'], y_pred,\n",
        "    target_names=[\"Negative Review\", \"Positive Review\"]\n",
        "\n",
        ")\n",
        "\n",
        "print(performance_roberta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJAOtkYpQqig",
        "outputId": "dd52ee06-fd6b-4498-b2da-d32fe8f40fa8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.81      0.69      0.75       533\n",
            "Positive Review       0.73      0.84      0.78       533\n",
            "\n",
            "       accuracy                           0.77      1066\n",
            "      macro avg       0.77      0.77      0.77      1066\n",
            "   weighted avg       0.77      0.77      0.77      1066\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding models"
      ],
      "metadata": {
        "id": "dVK9Ry8uRpiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next approach will utilyze embedding models to generate vector representations for each comment. Then, a lightweight classifier will be trained on top of those representations."
      ],
      "metadata": {
        "id": "0NJQaLAWVIOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "train_embeddings = model.encode(dataset[\"train\"][\"text\"])\n",
        "test_embeddings = model.encode(dataset[\"test\"][\"text\"])"
      ],
      "metadata": {
        "id": "Hfca4cwrQ6eA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a KNN and printing the performance."
      ],
      "metadata": {
        "id": "o7lijCkcVZ3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KNeighborsClassifier()\n",
        "clf.fit(train_embeddings, dataset[\"train\"][\"label\"])\n",
        "\n",
        "performance_mpnet = classification_report(\n",
        "    dataset['test']['label'], clf.predict(test_embeddings),\n",
        "    target_names=[\"Negative Review\", \"Positive Review\"]\n",
        ")\n",
        "\n",
        "print(performance_mpnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJJq7LQ1R-ee",
        "outputId": "c9f6e1c5-043e-4bac-9420-ee1067f3fa11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.85      0.75      0.79       533\n",
            "Positive Review       0.77      0.86      0.82       533\n",
            "\n",
            "       accuracy                           0.81      1066\n",
            "      macro avg       0.81      0.81      0.81      1066\n",
            "   weighted avg       0.81      0.81      0.81      1066\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-shot classification"
      ],
      "metadata": {
        "id": "O-kqsb1ND-83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some situations, there are no labels available to each data point. But one may want to classify the documents based on some list of groups. For that, one can embed the documents and a text that represents each label, and then classify them based on cossine similarity."
      ],
      "metadata": {
        "id": "Nft_sTV_ECDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_embeddings1 = model.encode([\"A negative review\", \"A positive review\"])\n",
        "label_embeddings2 = model.encode([\"A very negative movie review\", \"A very positive movie review\"])\n",
        "\n",
        "sim_matrix1 = cosine_similarity(test_embeddings, label_embeddings1)\n",
        "y_pred1 = np.argmax(sim_matrix1, axis=1)\n",
        "\n",
        "sim_matrix2 = cosine_similarity(test_embeddings, label_embeddings2)\n",
        "y_pred2 = np.argmax(sim_matrix2, axis=1)\n",
        "\n",
        "performance_zero_shot1 = classification_report(\n",
        "    dataset['test']['label'], y_pred1,\n",
        "    target_names=[\"Negative Review\", \"Positive Review\"]\n",
        ")\n",
        "\n",
        "performance_zero_shot2 = classification_report(\n",
        "    dataset['test']['label'], y_pred2,\n",
        "    target_names=[\"Negative Review\", \"Positive Review\"]\n",
        ")\n",
        "\n",
        "print(performance_zero_shot1)\n",
        "print()\n",
        "print(performance_zero_shot2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qieq9oATD1f3",
        "outputId": "5105a920-f8a2-4e71-908a-81dd8432fbb9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.78      0.77      0.78       533\n",
            "Positive Review       0.77      0.79      0.78       533\n",
            "\n",
            "       accuracy                           0.78      1066\n",
            "      macro avg       0.78      0.78      0.78      1066\n",
            "   weighted avg       0.78      0.78      0.78      1066\n",
            "\n",
            "\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.86      0.73      0.79       533\n",
            "Positive Review       0.76      0.88      0.82       533\n",
            "\n",
            "       accuracy                           0.80      1066\n",
            "      macro avg       0.81      0.80      0.80      1066\n",
            "   weighted avg       0.81      0.80      0.80      1066\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative models"
      ],
      "metadata": {
        "id": "smfKaPptJLu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will use a generative model to classify the reviews. For that, we need to create a prompt such that the text generated by the model can be further converted into a proper label."
      ],
      "metadata": {
        "id": "udJydkqGMB2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipe = pipeline(\n",
        "    task=\"text2text-generation\",\n",
        "    model=\"google/flan-t5-small\",\n",
        "    device=\"cuda:0\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsVDBt05JNSl",
        "outputId": "46f99d29-6e55-4ef1-ca1f-0d289beb4822"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the prompt and predicting the data."
      ],
      "metadata": {
        "id": "lOdDjLZ-MQDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Is the following sentence positive or negative?\"\n",
        "dataset = dataset.map(lambda example: {\"t5\": prompt + example['text']})\n",
        "\n",
        "y_pred = []\n",
        "for output in model(KeyDataset(dataset[\"test\"], \"t5\")):\n",
        "    text = output[0][\"generated_text\"]\n",
        "    y_pred.append(0 if text == \"negative\" else 1)"
      ],
      "metadata": {
        "id": "-q5PDa-KKBr-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the performance."
      ],
      "metadata": {
        "id": "ZTq0dc6UMUPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "performance_flan = classification_report(\n",
        "    dataset['test']['label'], y_pred,\n",
        "    target_names=[\"Negative Review\", \"Positive Review\"]\n",
        ")\n",
        "\n",
        "print(performance_flan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUXGMBzfKrk-",
        "outputId": "31b347a1-4f99-4703-d795-2f0e08419592"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.83      0.84      0.83       533\n",
            "Positive Review       0.84      0.83      0.83       533\n",
            "\n",
            "       accuracy                           0.83      1066\n",
            "      macro avg       0.83      0.83      0.83      1066\n",
            "   weighted avg       0.83      0.83      0.83      1066\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
